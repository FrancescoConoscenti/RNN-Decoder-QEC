{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1]\n",
      "[[0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "distance=3\n",
    "num_ancilla_qubits=8\n",
    "rounds=5\n",
    "\n",
    "surface_code_circuit = stim.Circuit.generated(\n",
    "    \"surface_code:rotated_memory_x\",\n",
    "    rounds=5,\n",
    "    distance=3,\n",
    "    after_clifford_depolarization=0.01,\n",
    "    after_reset_flip_probability=0.01,\n",
    "    before_measure_flip_probability=0.01,\n",
    "    before_round_data_depolarization=0.01)\n",
    "\n",
    "num_shots=64*1000\n",
    "# Compile the sampler\n",
    "sampler = surface_code_circuit.compile_detector_sampler()\n",
    "# Sample shots, with observables\n",
    "detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "\n",
    "detection_events = detection_events.astype(int)\n",
    "detection_strings = [''.join(map(str, row)) for row in detection_events] #compress the detection events in a tensor\n",
    "detection_events_numeric = [[int(value) for value in row] for row in detection_events] # Convert string elements to integers (or floats if needed)\n",
    "detection_array = np.array(detection_events_numeric) # Convert detection_events to a numpy array\n",
    "print(detection_array[0])\n",
    "\n",
    "detection_array1 = detection_array.reshape(num_shots, rounds, num_ancilla_qubits) #first dim is the number of shots, second dim round number, third dim is the Ancilla \n",
    "print(detection_array1[0]) \n",
    "\n",
    "observable_flips = observable_flips.astype(int).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class LatticeRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,batch_size):\n",
    "        super(LatticeRNNCell, self).__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.hidden=hidden_size\n",
    "        self.fc_input = nn.Linear(input_size, input_size)\n",
    "        self.fc_hidden_double = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc_hidden_single = nn.Linear(hidden_size, hidden_size)\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden_left, hidden_up):\n",
    "        # if hidden_left is not None and hidden_bottom is not None:\n",
    "        #     hidden = (hidden_left + hidden_bottom) / 2  # Average of left and bottom\n",
    "        # elif hidden_left is not None:\n",
    "        #     hidden = hidden_left\n",
    "        # elif hidden_bottom is not None:\n",
    "        #     hidden = hidden_bottom\n",
    "        # else:\n",
    "        #     hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        \n",
    "        #input fc net\n",
    "        #input=self.fc_input(x.type(torch.FloatTensor))\n",
    "\n",
    "        # Combine the hidden states from left and bottom\n",
    "        if hidden_left is not None and hidden_up is not None:\n",
    "            combined_hidden=torch.cat((hidden_left,hidden_up),1)\n",
    "            hidden=self.fc_hidden_double(combined_hidden.squeeze(0))\n",
    "\n",
    "        elif hidden_left is not None:\n",
    "            hidden=self.fc_hidden_single(hidden_left)\n",
    "\n",
    "        elif hidden_up is not None:\n",
    "            hidden=self.fc_hidden_single(hidden_up)\n",
    "            \n",
    "        else:\n",
    "            hidden=torch.zeros(self.batch_size,self.hidden, dtype=torch.float)\n",
    "\n",
    "        x=x.squeeze(1).float()\n",
    "\n",
    "        # Update hidden state using current input and combined hidden state\n",
    "        hidden = self.rnn_cell(x, hidden)\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "class LatticeRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, grid_height, grid_width,batch_size):\n",
    "        super(LatticeRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.grid_height = grid_height\n",
    "        self.grid_width = grid_width \n",
    "        self.rnn_cells = nn.ModuleList([LatticeRNNCell(input_size, hidden_size,batch_size) for _ in range(grid_height * grid_width)])\n",
    "        self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, hidden_ext):\n",
    "        # Initialize a grid of hidden states\n",
    "        grid = [[None for _ in range(self.grid_width)] for _ in range(self.grid_height)]\n",
    "        \n",
    "        # Reshape the input to match the grid size\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = x.reshape(batch_size, self.grid_height, self.grid_width)\n",
    "\n",
    "        for i in range(self.grid_height):\n",
    "            for j in range(self.grid_width):\n",
    "                input_bit = x[:,i,j].unsqueeze(1).unsqueeze(1) # Get the input for the current cell\n",
    "                if j==0 & i==0:\n",
    "                    hidden_left = hidden_ext\n",
    "                hidden_left = grid[i][j - 1] if j > 0 else None\n",
    "                hidden_up = grid[i - 1][j] if i > 0 else None\n",
    "\n",
    "                # Get the index for the current RNN cell\n",
    "                cell_index = i * self.grid_width + j\n",
    "                hidden = self.rnn_cells[cell_index](input_bit, hidden_left, hidden_up)\n",
    "\n",
    "                # Store the hidden state in the grid\n",
    "                grid[i][j] = hidden\n",
    "\n",
    "        # The output that matters is the hidden state from the top-right corner (i.e., grid[grid_size-1][grid_size-1])\n",
    "        bottom_right_hidden = grid[-1][-1]\n",
    "\n",
    "        # Pass the hidden state through the fully connected layer and sigmoid for binary output\n",
    "        hidden= self.fc_hidden(bottom_right_hidden)\n",
    "        output = self.fc_out(bottom_right_hidden)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "\n",
    "# RNN model\n",
    "class BlockRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, grid_height, grid_width, rounds,batch_size):\n",
    "        super(BlockRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.fc_in = nn.Linear(input_size, input_size)\n",
    "        self.rnn_block = LatticeRNN(input_size, hidden_size, output_size, grid_height, grid_width,batch_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, rounds):\n",
    "        #input=self.fc_in(x)\n",
    "\n",
    "        hidden_ext = torch.zeros(1,1,self.hidden_size)\n",
    "\n",
    "        for round in range (rounds):\n",
    "            input_block = x[:,round,:].unsqueeze(2)  # (1, 8)\n",
    "            out, hidden_ext = self.rnn_block(input_block, hidden_ext)\n",
    "\n",
    "        #I already use fc, sigmoid in the LatticeRNN\n",
    "        #out = self.fc_out(out)  # Use the last time-step's output, needed for changing the dimension of the output compared of input\n",
    "        #out = self.sigmoid(out)  # I need a Binary output\n",
    "        return out, hidden_ext\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(model, X_train, y_train, criterion, optimizer, num_epochs, batch_size,rounds):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    num_samples = len(X_train[:,0,0])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            # Create mini-batches\n",
    "            batch_x = torch.from_numpy(X_train[i:i + batch_size])\n",
    "            batch_y = torch.Tensor(y_train[i:i + batch_size])\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            #hidden = model.init_hidden(1)\n",
    "            output, hidden = model(batch_x, rounds)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output.squeeze(1), batch_y)\n",
    "\n",
    "            # Backward pass (compute gradients)\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize (update weights)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for logging purposes\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss after each epoch\n",
    "        avg_loss = running_loss / (num_samples // batch_size)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "\n",
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_array_to_tensor(binary_array):\n",
    "    # Check if the input is a NumPy array, if not, convert it\n",
    "    if isinstance(binary_array, np.ndarray):\n",
    "        tensor = torch.from_numpy(binary_array).float()  # Convert NumPy array to float32 tensor\n",
    "    else:\n",
    "        # If not a NumPy array, convert it as before\n",
    "        tensor = torch.tensor([[int(bit) for bit in binary_array]], dtype=torch.float32)\n",
    "    return tensor.unsqueeze(0)  # Add batch dimension (batch_size = 1)\n",
    "\n",
    "\n",
    "def test(model, test_sequences, targets,batch_size):\n",
    "    model.eval()  # Set the model to evaluation mode (disable dropout, etc.)\n",
    "    correct = 0\n",
    "\n",
    "    hidden = None\n",
    "    num_samples = len(test_sequences[:,0,0])\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            \n",
    "            output=np.zeros(batch_size)\n",
    "            batch_x = torch.from_numpy(test_sequences[i:i + batch_size])\n",
    "            target = targets[i:i + batch_size]\n",
    "            rounds = len(batch_x[0,:,0])\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            #if hidden is None:\n",
    "                # Initialize hidden state for the first sequence (or batch)\n",
    "            #    hidden = model.init_hidden(batch_size=1)  # batch_size might vary depending on your use case\n",
    "            #else:\n",
    "                #hidden=hidden.detach() #you detach if you want to avoid that the gradient is propagated through the hidden states to avoid long training time and memory usage\n",
    "            \n",
    "            # Forward pass for prediction\n",
    "            output, hidden = model(batch_x, rounds)\n",
    "            prediction = torch.round(output)  # Convert probability to binary (0 or 1)\n",
    "            \n",
    "            for j in range(0,batch_size):\n",
    "                if prediction[j] == target[j]:\n",
    "                    correct += 1\n",
    "    \n",
    "    accuracy = correct / len(test_sequences)\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3062,  0.4015, -0.2562, -0.3896, -0.5514, -0.0314,  0.1505,  0.0270],\n",
      "        [ 0.2465,  0.4035, -0.2727, -0.3833, -0.5616, -0.0133,  0.0472,  0.0846],\n",
      "        [ 0.2950,  0.4290, -0.3010, -0.3025, -0.4334,  0.0086,  0.1513, -0.1035],\n",
      "        [ 0.3192,  0.4385, -0.2344, -0.3907, -0.5375, -0.0356,  0.2179, -0.0477],\n",
      "        [ 0.3422,  0.3191, -0.3343, -0.3070, -0.4557, -0.0264,  0.1090,  0.0442],\n",
      "        [ 0.4217,  0.3554, -0.2596, -0.3383, -0.4226, -0.0451,  0.3365, -0.1198],\n",
      "        [ 0.2907,  0.3915, -0.2952, -0.3299, -0.4855, -0.0123,  0.1034,  0.0133],\n",
      "        [ 0.3113,  0.3758, -0.2907, -0.3444, -0.4933, -0.0217,  0.1315,  0.0126],\n",
      "        [ 0.2349,  0.4226, -0.2889, -0.3539, -0.5222,  0.0049,  0.0420,  0.0297],\n",
      "        [ 0.2229,  0.4013, -0.2868, -0.3709, -0.5487, -0.0009,  0.0035,  0.0950],\n",
      "        [ 0.3017,  0.3150, -0.3609, -0.2890, -0.4520, -0.0075,  0.0202,  0.0850],\n",
      "        [ 0.1088,  0.3646, -0.3313, -0.3827, -0.5830,  0.0297, -0.2163,  0.2385],\n",
      "        [ 0.3636,  0.3945, -0.2469, -0.3848, -0.5237, -0.0419,  0.2511, -0.0421],\n",
      "        [ 0.1901,  0.3680, -0.3335, -0.3362, -0.5220,  0.0202, -0.0980,  0.1461],\n",
      "        [ 0.1855,  0.3479, -0.3610, -0.3196, -0.5025,  0.0315, -0.1304,  0.1489],\n",
      "        [ 0.3035,  0.3560, -0.2956, -0.3634, -0.5325, -0.0272,  0.0841,  0.0843],\n",
      "        [ 0.3390,  0.3813, -0.3179, -0.2768, -0.3962, -0.0080,  0.1827, -0.0935],\n",
      "        [ 0.1462,  0.3368, -0.3777, -0.3198, -0.5096,  0.0420, -0.2066,  0.1953],\n",
      "        [ 0.3816,  0.3760, -0.2648, -0.3413, -0.4568, -0.0400,  0.2665, -0.0721],\n",
      "        [ 0.2352,  0.3869, -0.2902, -0.3740, -0.5551, -0.0060,  0.0077,  0.1091],\n",
      "        [ 0.2416,  0.4320, -0.2559, -0.3911, -0.5694, -0.0123,  0.0677,  0.0583],\n",
      "        [ 0.3788,  0.3279, -0.3061, -0.3293, -0.4666, -0.0401,  0.1876,  0.0087],\n",
      "        [ 0.3523,  0.3620, -0.3077, -0.2987, -0.4230, -0.0202,  0.1917, -0.0567],\n",
      "        [ 0.3402,  0.3740, -0.2912, -0.3252, -0.4669, -0.0254,  0.1716, -0.0160],\n",
      "        [ 0.3532,  0.3566, -0.3093, -0.2989, -0.4167, -0.0195,  0.1932, -0.0604],\n",
      "        [ 0.3002,  0.3864, -0.2817, -0.3553, -0.5114, -0.0217,  0.1209,  0.0261],\n",
      "        [ 0.1582,  0.3954, -0.3003, -0.3728, -0.5638,  0.0179, -0.1129,  0.1717],\n",
      "        [ 0.3489,  0.3627, -0.2989, -0.3186, -0.4468, -0.0251,  0.1898, -0.0410],\n",
      "        [ 0.2677,  0.3121, -0.3774, -0.2831, -0.4347,  0.0181, -0.0219,  0.0703],\n",
      "        [ 0.3826,  0.2802, -0.3770, -0.2355, -0.3407, -0.0140,  0.1516, -0.0388],\n",
      "        [ 0.3540,  0.3313, -0.3285, -0.2907, -0.4110, -0.0193,  0.1625, -0.0309],\n",
      "        [ 0.2686,  0.3953, -0.3196, -0.3074, -0.4585,  0.0104,  0.0652, -0.0095],\n",
      "        [ 0.4403,  0.2904, -0.3239, -0.2665, -0.3463, -0.0406,  0.2788, -0.0841],\n",
      "        [ 0.2696,  0.4276, -0.2415, -0.4077, -0.5858, -0.0242,  0.1104,  0.0559],\n",
      "        [ 0.3117,  0.3212, -0.3628, -0.2774, -0.4284, -0.0044,  0.0540,  0.0374],\n",
      "        [ 0.3514,  0.3999, -0.2808, -0.3117, -0.4157, -0.0183,  0.2456, -0.1255],\n",
      "        [ 0.3110,  0.4019, -0.2868, -0.3281, -0.4692, -0.0141,  0.1567, -0.0393],\n",
      "        [ 0.4024,  0.3942, -0.2397, -0.3464, -0.4212, -0.0392,  0.3537, -0.1636],\n",
      "        [ 0.1988,  0.4150, -0.2856, -0.3721, -0.5585,  0.0045, -0.0254,  0.1068],\n",
      "        [ 0.2275,  0.3952, -0.2768, -0.3925, -0.5793, -0.0096,  0.0060,  0.1233],\n",
      "        [ 0.4198,  0.3431, -0.2738, -0.3229, -0.4065, -0.0434,  0.3182, -0.1110],\n",
      "        [ 0.3279,  0.3204, -0.3312, -0.3279, -0.4930, -0.0295,  0.0801,  0.0822],\n",
      "        [ 0.0960,  0.4179, -0.2898, -0.4007, -0.5961,  0.0330, -0.1850,  0.2048],\n",
      "        [ 0.3849,  0.3235, -0.3292, -0.2686, -0.3731, -0.0244,  0.2116, -0.0677],\n",
      "        [ 0.3255,  0.2976, -0.3854, -0.2507, -0.3813,  0.0040,  0.0556,  0.0135],\n",
      "        [ 0.1948,  0.3599, -0.3368, -0.3374, -0.5169,  0.0200, -0.0936,  0.1412],\n",
      "        [ 0.2917,  0.3825, -0.2888, -0.3476, -0.5044, -0.0147,  0.1021,  0.0327],\n",
      "        [ 0.3300,  0.3795, -0.2998, -0.3146, -0.4516, -0.0178,  0.1698, -0.0421],\n",
      "        [ 0.1402,  0.4602, -0.2454, -0.4276, -0.6264,  0.0142, -0.0701,  0.1418],\n",
      "        [ 0.2121,  0.3750, -0.3314, -0.3312, -0.5091,  0.0196, -0.0526,  0.1005],\n",
      "        [ 0.3820,  0.3436, -0.3121, -0.2799, -0.3713, -0.0225,  0.2430, -0.1067],\n",
      "        [ 0.3771,  0.3702, -0.2837, -0.3084, -0.4074, -0.0302,  0.2599, -0.1031],\n",
      "        [ 0.2969,  0.3436, -0.3391, -0.3006, -0.4474, -0.0023,  0.0644,  0.0271],\n",
      "        [ 0.2645,  0.3648, -0.3067, -0.3500, -0.5203, -0.0108,  0.0321,  0.0904],\n",
      "        [ 0.2725,  0.4206, -0.2646, -0.3711, -0.5385, -0.0171,  0.1079,  0.0252],\n",
      "        [ 0.4446,  0.3179, -0.2870, -0.2800, -0.3297, -0.0382,  0.3474, -0.1489],\n",
      "        [ 0.3571,  0.3106, -0.3475, -0.2835, -0.4254, -0.0239,  0.1195,  0.0249],\n",
      "        [ 0.3177,  0.3903, -0.3035, -0.3103, -0.4380, -0.0072,  0.1618, -0.0669],\n",
      "        [ 0.1075,  0.4414, -0.2649, -0.4213, -0.6143,  0.0280, -0.1388,  0.1754],\n",
      "        [ 0.2194,  0.3932, -0.2877, -0.3761, -0.5555, -0.0021, -0.0112,  0.1156],\n",
      "        [ 0.3279,  0.2936, -0.3834, -0.2578, -0.4000, -0.0034,  0.0491,  0.0396],\n",
      "        [ 0.2578,  0.4070, -0.3081, -0.3231, -0.4766,  0.0115,  0.0639, -0.0073],\n",
      "        [ 0.2500,  0.4330, -0.2640, -0.3723, -0.5459, -0.0123,  0.0793,  0.0361],\n",
      "        [ 0.3137,  0.3685, -0.2975, -0.3409, -0.4930, -0.0224,  0.1272,  0.0181]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 1  # Each RNN cell takes 1 bit as input\n",
    "hidden_size = 8 # Hidden size of each RNN cell\n",
    "output_size = 1  # Binary output\n",
    "grid_height = 4  # 4x2 grid of RNN cells\n",
    "grid_width= 2\n",
    "batch_size = 64\n",
    "\n",
    "model = LatticeRNN(input_size, hidden_size, output_size, grid_height, grid_width,batch_size)\n",
    "\n",
    "# Input is a batch of binary sequences (batch_size, seq_len, input_size), reshaped to match grid size\n",
    "seq_len = grid_height * grid_width  # Number of bits equal to the grid size squared\n",
    "x = torch.randn(batch_size, seq_len, input_size)  # Random input, replace with binary input\n",
    "hidden_ext = torch.randn(batch_size, hidden_size)  # Random input, replace with binary input\n",
    "\n",
    "output, hidden = model(x,hidden_ext)\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3981\n",
      "Epoch [2/10], Loss: 0.3831\n",
      "Epoch [3/10], Loss: 0.3794\n",
      "Epoch [4/10], Loss: 0.3770\n",
      "Epoch [5/10], Loss: 0.3753\n",
      "Epoch [6/10], Loss: 0.3730\n",
      "Epoch [7/10], Loss: 0.3715\n",
      "Epoch [8/10], Loss: 0.3708\n",
      "Epoch [9/10], Loss: 0.3728\n",
      "Epoch [10/10], Loss: 0.3729\n",
      "Training finished.\n",
      "Test Accuracy: 86.29%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1  # Each Lattice RNN cell takes 1 bit as input\n",
    "hidden_size = 64  # Hidden size of each RNN cell\n",
    "output_size = 1  # Binary output (e.g., 0 or 1)\n",
    "grid_height = 2  # Number of rows in the grid\n",
    "grid_width = 4   # Number of columns in the grid\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a model instance\n",
    "model = BlockRNN(input_size, hidden_size, output_size, grid_height, grid_width, rounds,batch_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "test_size=0.2\n",
    "test_dataset_size=num_shots*test_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(detection_array1, observable_flips, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Training the model\n",
    "train_rnn(model, X_train, y_train, criterion, optimizer, num_epochs,batch_size,rounds)\n",
    "\n",
    "test(model, X_test, y_test,batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
