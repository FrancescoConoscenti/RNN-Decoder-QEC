{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[[0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import perf_counter\n",
    "\n",
    "distance=3\n",
    "num_ancilla_qubits=8\n",
    "rounds=5\n",
    "\n",
    "surface_code_circuit = stim.Circuit.generated(\n",
    "    \"surface_code:rotated_memory_x\",\n",
    "    rounds=rounds,\n",
    "    distance=3,\n",
    "    after_clifford_depolarization=0.01,\n",
    "    after_reset_flip_probability=0.01,\n",
    "    before_measure_flip_probability=0.01,\n",
    "    before_round_data_depolarization=0.01)\n",
    "\n",
    "\n",
    "num_shots=200000\n",
    "# Compile the sampler\n",
    "sampler = surface_code_circuit.compile_detector_sampler()\n",
    "# Sample shots, with observables\n",
    "detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "\n",
    "detection_events = detection_events.astype(int)\n",
    "detection_strings = [''.join(map(str, row)) for row in detection_events] #compress the detection events in a tensor\n",
    "detection_events_numeric = [[int(value) for value in row] for row in detection_events] # Convert string elements to integers (or floats if needed)\n",
    "detection_array = np.array(detection_events_numeric) # Convert detection_events to a numpy array\n",
    "print(detection_array[0])\n",
    "\n",
    "detection_array1 = detection_array.reshape(num_shots, rounds, num_ancilla_qubits) #first dim is the number of shots, second dim round number, third dim is the Ancilla \n",
    "print(detection_array1[0]) \n",
    "\n",
    "observable_flips = observable_flips.astype(int).flatten().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class LatticeRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,batch_size):\n",
    "        super(LatticeRNNCell, self).__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.hidden=hidden_size\n",
    "        self.fc_input = nn.Linear(input_size, input_size)\n",
    "        self.fc_hidden_double = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc_hidden_single = nn.Linear(hidden_size, hidden_size)\n",
    "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden_left, hidden_up):\n",
    "        # if hidden_left is not None and hidden_bottom is not None:\n",
    "        #     hidden = (hidden_left + hidden_bottom) / 2  # Average of left and bottom\n",
    "        # elif hidden_left is not None:\n",
    "        #     hidden = hidden_left\n",
    "        # elif hidden_bottom is not None:\n",
    "        #     hidden = hidden_bottom\n",
    "        # else:\n",
    "        #     hidden = torch.zeros(x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        \n",
    "        #input fc net\n",
    "        #input=self.fc_input(x.type(torch.FloatTensor))\n",
    "\n",
    "        # Combine the hidden states from left and bottom\n",
    "        if hidden_left is not None and hidden_up is not None:\n",
    "            combined_hidden=torch.cat((hidden_left,hidden_up),1)\n",
    "            hidden=self.fc_hidden_double(combined_hidden.squeeze(0))\n",
    "\n",
    "        elif hidden_left is not None:\n",
    "            hidden=self.fc_hidden_single(hidden_left)\n",
    "\n",
    "        elif hidden_up is not None:\n",
    "            hidden=self.fc_hidden_single(hidden_up)\n",
    "            \n",
    "        else:\n",
    "            hidden=torch.zeros(self.batch_size,self.hidden, dtype=torch.float)\n",
    "\n",
    "        x=x.squeeze(1).float()\n",
    "\n",
    "        # Update hidden state using current input and combined hidden state\n",
    "        hidden = self.rnn_cell(x, hidden)\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "class LatticeRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, grid_height, grid_width,batch_size):\n",
    "        super(LatticeRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.grid_height = grid_height\n",
    "        self.grid_width = grid_width \n",
    "        self.rnn_cells = nn.ModuleList([LatticeRNNCell(input_size, hidden_size,batch_size) for _ in range(grid_height * grid_width)])\n",
    "        self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, hidden_ext):\n",
    "        # Initialize a grid of hidden states\n",
    "        grid = [[None for _ in range(self.grid_width)] for _ in range(self.grid_height)]\n",
    "        \n",
    "        # Reshape the input to match the grid size\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = x.reshape(batch_size, self.grid_height, self.grid_width)\n",
    "\n",
    "        for i in range(self.grid_height):\n",
    "            for j in range(self.grid_width):\n",
    "                input_bit = x[:,i,j].unsqueeze(1).unsqueeze(1) # Get the input for the current cell\n",
    "                if j==0 & i==0:\n",
    "                    hidden_left = hidden_ext\n",
    "                hidden_left = grid[i][j - 1] if j > 0 else None\n",
    "                hidden_up = grid[i - 1][j] if i > 0 else None\n",
    "\n",
    "                # Get the index for the current RNN cell\n",
    "                cell_index = i * self.grid_width + j\n",
    "                hidden = self.rnn_cells[cell_index](input_bit, hidden_left, hidden_up)\n",
    "\n",
    "                # Store the hidden state in the grid\n",
    "                grid[i][j] = hidden\n",
    "\n",
    "        # The output that matters is the hidden state from the top-right corner (i.e., grid[grid_size-1][grid_size-1])\n",
    "        bottom_right_hidden = grid[-1][-1]\n",
    "\n",
    "        # Pass the hidden state through the fully connected layer and sigmoid for binary output\n",
    "        hidden= self.fc_hidden(bottom_right_hidden)\n",
    "        output = self.fc_out(bottom_right_hidden)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "\n",
    "# RNN model\n",
    "class BlockRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, grid_height, grid_width, rounds,batch_size):\n",
    "        super(BlockRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.fc_in = nn.Linear(input_size, input_size)\n",
    "        self.rnn_block = LatticeRNN(input_size, hidden_size, output_size, grid_height, grid_width,batch_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, rounds):\n",
    "        #input=self.fc_in(x)\n",
    "\n",
    "        hidden_ext = torch.zeros(1,1,self.hidden_size)\n",
    "\n",
    "        for round in range (rounds):\n",
    "            input_block = x[:,round,:].unsqueeze(2)  # (1, 8)\n",
    "            out, hidden_ext = self.rnn_block(input_block, hidden_ext)\n",
    "\n",
    "        #I already use fc, sigmoid in the LatticeRNN\n",
    "        #out = self.fc_out(out)  # Use the last time-step's output, needed for changing the dimension of the output compared of input\n",
    "        #out = self.sigmoid(out)  # I need a Binary output\n",
    "        return out, hidden_ext\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(model, X_train, y_train, criterion, optimizer, num_epochs, batch_size,rounds):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    num_batches = len(X_train[:,0,0]) // batch_size\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # Create mini-batches\n",
    "            batch_x = torch.from_numpy(X_train[batch_idx * batch_size : (batch_idx + 1) * batch_size])\n",
    "            batch_y = torch.Tensor(y_train[batch_idx * batch_size : (batch_idx + 1) * batch_size])\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            #hidden = model.init_hidden(1)\n",
    "            output, hidden = model(batch_x, rounds)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output.squeeze(1), batch_y)\n",
    "\n",
    "            # Backward pass (compute gradients)\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize (update weights)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for logging purposes\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss after each epoch\n",
    "        avg_loss = running_loss / num_batches \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "\n",
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_batch(batch_x, batch_y,i, model, criterion, rounds):\n",
    "    # Forward pass\n",
    "    outputs, hidden = model(batch_x, rounds)\n",
    "    loss = criterion(outputs.squeeze(1), batch_y)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Collect gradients\n",
    "    grads = [param.grad.clone() if param.grad is not None else torch.zeros_like(param)\n",
    "             for param in model.parameters()]\n",
    "    \n",
    "    print(i)\n",
    "    print(\"ff\")\n",
    "    \n",
    "    # Reduce gradients over batch dimension\n",
    "    #reduced_grads = [grad.sum(dim=0, keepdim=True) if len(grad.shape) > 1 else grad \n",
    "    #               for grad in grads]\n",
    "    \n",
    "    return loss.item(), grads\n",
    "\n",
    "\n",
    "def train_rnn_parallel(model,  X_train, y_train, criterion, optimizer,  num_epochs, batch_size, rounds, n_jobs=8):\n",
    "    \n",
    "    num_samples = len(X_train[:,0,0])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0  # Reset loss for each epoch\n",
    "\n",
    "        # Ensure model is in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Split data into batches\n",
    "        batches = [\n",
    "            (torch.from_numpy(X_train[i:i + batch_size]),\n",
    "            torch.Tensor(y_train[i:i + batch_size]))\n",
    "            for i in range(0, num_samples, batch_size)\n",
    "        ]\n",
    "\n",
    "        start= perf_counter()\n",
    "        #results = [process_batch(batch_x, batch_y,i, model, criterion, rounds) for i, (batch_x, batch_y) in enumerate(batches)]\n",
    "        results = Parallel(n_jobs=n_jobs,  backend='multiprocessing')(delayed(process_batch)(batch_x, batch_y,i,  model, criterion, rounds)for i, (batch_x, batch_y) in enumerate(batches))   \n",
    "        end_time = perf_counter()\n",
    "\n",
    "        elapsed_time = end_time - start\n",
    "        print(f\"Execution time: {elapsed_time:.6f} seconds\")\n",
    "        \n",
    "        # Aggregate results\n",
    "        optimizer.zero_grad()  # Clear gradients before aggregation\n",
    "        \n",
    "        for loss, grads in results:\n",
    "            running_loss += loss\n",
    "            for param, grad in zip(model.parameters(), grads):\n",
    "                if grad.shape != param.shape:\n",
    "                    raise ValueError(f\"Gradient shape {grad.shape} does not match parameter shape {param.shape}.\")\n",
    "                if param.grad is None:\n",
    "                    param.grad = grad.clone()  # Initialize gradient\n",
    "                else:\n",
    "                    param.grad += grad  # Accumulate gradient\n",
    "\n",
    "\n",
    "        # Step optimizer after aggregating all gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log the epoch's loss\n",
    "        avg_loss = running_loss / len(batches)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_array_to_tensor(binary_array):\n",
    "    # Check if the input is a NumPy array, if not, convert it\n",
    "    if isinstance(binary_array, np.ndarray):\n",
    "        tensor = torch.from_numpy(binary_array).float()  # Convert NumPy array to float32 tensor\n",
    "    else:\n",
    "        # If not a NumPy array, convert it as before\n",
    "        tensor = torch.tensor([[int(bit) for bit in binary_array]], dtype=torch.float32)\n",
    "    return tensor.unsqueeze(0)  # Add batch dimension (batch_size = 1)\n",
    "\n",
    "\n",
    "def test(model, test_sequences, targets,batch_size):\n",
    "    model.eval()  # Set the model to evaluation mode (disable dropout, etc.)\n",
    "    correct = 0\n",
    "\n",
    "    hidden = None\n",
    "    num_batches = len(test_sequences[:,0,0]) // batch_size\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        for batch_idx in range(num_batches):\n",
    "        \n",
    "            output=np.zeros(batch_size)\n",
    "            batch_x = torch.from_numpy(test_sequences[batch_idx * batch_size : (batch_idx + 1) * batch_size])\n",
    "            target = targets[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            rounds = len(batch_x[0,:,0])\n",
    "            \n",
    "            \n",
    "            # Initialize hidden state\n",
    "            #if hidden is None:\n",
    "                # Initialize hidden state for the first sequence (or batch)\n",
    "            #    hidden = model.init_hidden(batch_size=1)  # batch_size might vary depending on your use case\n",
    "            #else:\n",
    "                #hidden=hidden.detach() #you detach if you want to avoid that the gradient is propagated through the hidden states to avoid long training time and memory usage\n",
    "            \n",
    "            # Forward pass for prediction\n",
    "            output, hidden = model(batch_x, rounds)\n",
    "            prediction = torch.round(output)  # Convert probability to binary (0 or 1)\n",
    "            \n",
    "            for j in range(0,batch_size):\n",
    "                if prediction[j] == target[j]:\n",
    "                    correct += 1\n",
    "    \n",
    "    accuracy = correct / len(test_sequences)\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2410,  0.2125,  0.2903,  0.4547,  0.1688, -0.1441, -0.2501, -0.1131],\n",
      "        [-0.1933,  0.3388,  0.3064,  0.3416,  0.2387, -0.1735, -0.0624, -0.2155],\n",
      "        [-0.2317, -0.0493,  0.1549,  0.7495,  0.0567, -0.1378, -0.8352,  0.1802],\n",
      "        [-0.2321,  0.3631,  0.3035,  0.3913,  0.1640, -0.2374, -0.0399, -0.1911],\n",
      "        [-0.2172,  0.0358,  0.3134,  0.5015,  0.2298, -0.0029, -0.4833, -0.0058],\n",
      "        [-0.2229, -0.1304,  0.1237,  0.7590, -0.0291, -0.0947, -0.9266,  0.3070],\n",
      "        [-0.2852,  0.2345,  0.2443,  0.5571,  0.0788, -0.2486, -0.3178, -0.0665],\n",
      "        [-0.2038,  0.1431,  0.2477,  0.5272,  0.2322, -0.1272, -0.4442, -0.0931],\n",
      "        [-0.2464,  0.2513,  0.2731,  0.4776,  0.1478, -0.1999, -0.2314, -0.1261],\n",
      "        [-0.2571,  0.2972,  0.2874,  0.4857,  0.1523, -0.2365, -0.1976, -0.1369],\n",
      "        [-0.2262,  0.2685,  0.3179,  0.3748,  0.1932, -0.1387, -0.1195, -0.1609],\n",
      "        [-0.2277, -0.0410,  0.2376,  0.6245,  0.1256, -0.0426, -0.6817,  0.1212],\n",
      "        [-0.1900,  0.1132,  0.2852,  0.4826,  0.2765, -0.0582, -0.4285, -0.0954],\n",
      "        [-0.2231,  0.1803,  0.2940,  0.4455,  0.1993, -0.1067, -0.2813, -0.1111],\n",
      "        [-0.2671,  0.1884,  0.2298,  0.6330,  0.1286, -0.2403, -0.4659, -0.0464],\n",
      "        [-0.2355,  0.2318,  0.2766,  0.5150,  0.1948, -0.1895, -0.3123, -0.1191],\n",
      "        [-0.2225,  0.2719,  0.2500,  0.4936,  0.1862, -0.2238, -0.2671, -0.1500],\n",
      "        [-0.2581,  0.0557,  0.1695,  0.7442,  0.0788, -0.2173, -0.7046,  0.0695],\n",
      "        [-0.2120,  0.1058,  0.2790,  0.5561,  0.2406, -0.0981, -0.4836, -0.0603],\n",
      "        [-0.2359, -0.0060,  0.2259,  0.6887,  0.1229, -0.1051, -0.7098,  0.1098],\n",
      "        [-0.1996,  0.3578,  0.3161,  0.3258,  0.2184, -0.1841, -0.0065, -0.2211],\n",
      "        [-0.2808,  0.2087,  0.2178,  0.6197,  0.0785, -0.2682, -0.4084, -0.0499],\n",
      "        [-0.2208,  0.1231,  0.2520,  0.5805,  0.2104, -0.1390, -0.4974, -0.0557],\n",
      "        [-0.2573,  0.2602,  0.2691,  0.5123,  0.1375, -0.2274, -0.2531, -0.1184],\n",
      "        [-0.2876,  0.1400,  0.2348,  0.6335,  0.0864, -0.2080, -0.4929,  0.0052],\n",
      "        [-0.2412,  0.1993,  0.2804,  0.4755,  0.1686, -0.1483, -0.2883, -0.1038],\n",
      "        [-0.2150,  0.2883,  0.2910,  0.3893,  0.2022, -0.1686, -0.1402, -0.1770],\n",
      "        [-0.2342,  0.0990,  0.2617,  0.5658,  0.1845, -0.1125, -0.4918, -0.0284],\n",
      "        [-0.2314,  0.0444,  0.2162,  0.6827,  0.1551, -0.1450, -0.6733,  0.0480],\n",
      "        [-0.2568,  0.0395,  0.2010,  0.6779,  0.0901, -0.1571, -0.6550,  0.0755],\n",
      "        [-0.2312,  0.3735,  0.2473,  0.4016,  0.1338, -0.2731, -0.0843, -0.1830],\n",
      "        [-0.2385,  0.2721,  0.2976,  0.4733,  0.1985, -0.1964, -0.2273, -0.1425],\n",
      "        [-0.2413,  0.0936,  0.2291,  0.6287,  0.1625, -0.1550, -0.5700, -0.0054],\n",
      "        [-0.2175,  0.3045,  0.2650,  0.4257,  0.1837, -0.2126, -0.1673, -0.1737],\n",
      "        [-0.2507, -0.0232,  0.1770,  0.7479,  0.0510, -0.1500, -0.7838,  0.1626],\n",
      "        [-0.2287,  0.1653,  0.3021,  0.4721,  0.2149, -0.1017, -0.3304, -0.0943],\n",
      "        [-0.2366, -0.0142,  0.1726,  0.7534,  0.0829, -0.1587, -0.7957,  0.1396],\n",
      "        [-0.2550,  0.0479,  0.2252,  0.6413,  0.1077, -0.1345, -0.6006,  0.0543],\n",
      "        [-0.2855,  0.0338,  0.1932,  0.6981,  0.0258, -0.1738, -0.6668,  0.1253],\n",
      "        [-0.2587,  0.1681,  0.2598,  0.5867,  0.1540, -0.1857, -0.4303, -0.0537],\n",
      "        [-0.2333,  0.2492,  0.2536,  0.5369,  0.1887, -0.2251, -0.3274, -0.1278],\n",
      "        [-0.2535,  0.1029,  0.2427,  0.6104,  0.1393, -0.1530, -0.5194, -0.0044],\n",
      "        [-0.2705,  0.2036,  0.2103,  0.6318,  0.0976, -0.2674, -0.4383, -0.0556],\n",
      "        [-0.2108,  0.0135,  0.2352,  0.5799,  0.1792, -0.0601, -0.6013,  0.0279],\n",
      "        [-0.2529,  0.3317,  0.2992,  0.4285,  0.1469, -0.2348, -0.1067, -0.1570],\n",
      "        [-0.2314, -0.0562,  0.1474,  0.7494,  0.0493, -0.1364, -0.8491,  0.1913],\n",
      "        [-0.2663,  0.1482,  0.2321,  0.6798,  0.1432, -0.2275, -0.5559, -0.0116],\n",
      "        [-0.2345,  0.1764,  0.2572,  0.5763,  0.1913, -0.1824, -0.4253, -0.0822],\n",
      "        [-0.2279,  0.2709,  0.2588,  0.4876,  0.1828, -0.2185, -0.2566, -0.1454],\n",
      "        [-0.2873,  0.1012,  0.2235,  0.6612,  0.0670, -0.1963, -0.5473,  0.0384],\n",
      "        [-0.2595,  0.0319,  0.2006,  0.7293,  0.0828, -0.1741, -0.7028,  0.0985],\n",
      "        [-0.2624,  0.1874,  0.2622,  0.5522,  0.1358, -0.1900, -0.3672, -0.0667],\n",
      "        [-0.2861,  0.3041,  0.2324,  0.5463,  0.0552, -0.3100, -0.2368, -0.0981],\n",
      "        [-0.2366, -0.0304,  0.1806,  0.7042,  0.0790, -0.1196, -0.7682,  0.1480],\n",
      "        [-0.2334,  0.2823,  0.3017,  0.4206,  0.1909, -0.1781, -0.1635, -0.1572],\n",
      "        [-0.2829,  0.2435,  0.2347,  0.5657,  0.0797, -0.2632, -0.3251, -0.0715],\n",
      "        [-0.2532,  0.1030,  0.1924,  0.7030,  0.1214, -0.2215, -0.6275,  0.0137],\n",
      "        [-0.2591,  0.0656,  0.2006,  0.7005,  0.1009, -0.1881, -0.6504,  0.0537],\n",
      "        [-0.2819,  0.0928,  0.1938,  0.7331,  0.0620, -0.2357, -0.6331,  0.0547],\n",
      "        [-0.2677,  0.0563,  0.1844,  0.7188,  0.0687, -0.2008, -0.6750,  0.0785],\n",
      "        [-0.2912,  0.1629,  0.2293,  0.6189,  0.0655, -0.2278, -0.4441, -0.0095],\n",
      "        [-0.2273,  0.3706,  0.2787,  0.4117,  0.1695, -0.2599, -0.0808, -0.1924],\n",
      "        [-0.2694,  0.1457,  0.2209,  0.6507,  0.1144, -0.2193, -0.5204, -0.0153],\n",
      "        [-0.2742,  0.3093,  0.2762,  0.4671,  0.0976, -0.2517, -0.1511, -0.1282]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_size = 1  # Each RNN cell takes 1 bit as input\n",
    "hidden_size = 8 # Hidden size of each RNN cell\n",
    "output_size = 1  # Binary output\n",
    "grid_height = 4  # 4x2 grid of RNN cells\n",
    "grid_width= 2\n",
    "batch_size = 64\n",
    "\n",
    "model = LatticeRNN(input_size, hidden_size, output_size, grid_height, grid_width,batch_size)\n",
    "\n",
    "# Input is a batch of binary sequences (batch_size, seq_len, input_size), reshaped to match grid size\n",
    "seq_len = grid_height * grid_width  # Number of bits equal to the grid size squared\n",
    "x = torch.randn(batch_size, seq_len, input_size)  # Random input, replace with binary input\n",
    "hidden_ext = torch.randn(batch_size, hidden_size)  # Random input, replace with binary input\n",
    "\n",
    "output, hidden = model(x,hidden_ext)\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5552\n",
      "Epoch [2/10], Loss: 0.5476\n",
      "Epoch [3/10], Loss: 0.5459\n",
      "Epoch [4/10], Loss: 0.5446\n",
      "Epoch [5/10], Loss: 0.5437\n",
      "Epoch [6/10], Loss: 0.5430\n",
      "Epoch [7/10], Loss: 0.5426\n",
      "Epoch [8/10], Loss: 0.5422\n",
      "Epoch [9/10], Loss: 0.5420\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1  # Each Lattice RNN cell takes 1 bit as input\n",
    "hidden_size = 64  # Hidden size of each RNN cell\n",
    "output_size = 1  # Binary output (e.g., 0 or 1)\n",
    "grid_height = 2  # Number of rows in the grid\n",
    "grid_width = 4   # Number of columns in the grid\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "# Create a model instance\n",
    "model = BlockRNN(input_size, hidden_size, output_size, grid_height, grid_width, rounds,batch_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "test_size=0.2\n",
    "test_dataset_size=num_shots*test_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(detection_array1, observable_flips, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Training the model\n",
    "train_rnn(model, X_train, y_train, criterion, optimizer, num_epochs,batch_size,rounds)\n",
    "\n",
    "test(model, X_test, y_test,batch_size)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
