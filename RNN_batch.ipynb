{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "path = r\"RNN-Decoder-QEC\\google_qec3v5_experiment_data\\surface_code_bX_d3_r05_center_3_5\\circuit_noisy.stim\"\n",
    "#circuit_google = stim.Circuit.from_file(path)\n",
    "\n",
    "distance=3\n",
    "rounds=5\n",
    "\n",
    "if distance ==3:\n",
    "    num_qubits=17\n",
    "    num_data_qubits=9\n",
    "    num_ancilla_qubits=8\n",
    "\n",
    "if distance ==5:\n",
    "    num_qubits=49\n",
    "    num_data_qubits=25\n",
    "    num_ancilla_qubits=24\n",
    "\n",
    "#circuit_google.diagram('timeline-svg')\n",
    "\n",
    "# # Compile the sampler\n",
    "# sampler = circuit.compile_detector_sampler()\n",
    "# # Sample shots, with observables\n",
    "# samples = sampler.sample(1, separate_observables=True)\n",
    "# print(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_surface = stim.Circuit.generated(\n",
    "    \"surface_code:rotated_memory_x\",\n",
    "    rounds=5,\n",
    "    distance=3,\n",
    "    after_clifford_depolarization=0.01,\n",
    "    after_reset_flip_probability=0.01,\n",
    "    before_measure_flip_probability=0.01,\n",
    "    before_round_data_depolarization=0.01)\n",
    "\n",
    "#circuit_surface.diagram(\"timeline-svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots=20000\n",
    "# Compile the sampler\n",
    "sampler = circuit_surface.compile_detector_sampler()\n",
    "# Sample shots, with observables\n",
    "detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "\n",
    "detection_events = detection_events.astype(int)\n",
    "detection_strings = [''.join(map(str, row)) for row in detection_events] #compress the detection events in a tensor\n",
    "detection_events_numeric = [[int(value) for value in row] for row in detection_events] # Convert string elements to integers (or floats if needed)\n",
    "detection_array = np.array(detection_events_numeric) # Convert detection_events to a numpy array\n",
    "\n",
    "detection_array1 = detection_array.reshape(num_shots, rounds, num_ancilla_qubits) #first dim is the number of shots, second dim round number, third dim is the Ancilla \n",
    "\n",
    "observable_flips = observable_flips.astype(int).flatten().tolist()\n",
    "\n",
    "\n",
    "test_size=0.2\n",
    "test_dataset_size=num_shots*test_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(detection_array1, observable_flips, test_size=0.2, random_state=42, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# RNN model\n",
    "class BinaryRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BinaryRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc = nn.Linear(input_size, input_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out1=out[:, -1, :]\n",
    "        out = self.fc(out1)  # Use the last time-step's output, needed for changing the dimension of the output compared of input\n",
    "        out = self.sigmoid(out)  # I need a Binary output\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "\n",
    "# LSTM model    \n",
    "class BinaryLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BinaryLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # For binary output\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time-step's output, needed for changing the dimension of the output compared of input\n",
    "        out = self.sigmoid(out)  # I need a Binary output\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),  # Hidden state\n",
    "                torch.zeros(1, batch_size, self.hidden_size))  # Cell state\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert binary string to tensor\n",
    "def binary_array_to_tensor(binary_array):\n",
    "    # Check if the input is a NumPy array, if not, convert it\n",
    "    if isinstance(binary_array, np.ndarray):\n",
    "        tensor = torch.from_numpy(binary_array).float()  # Convert NumPy array to float32 tensor\n",
    "    else:\n",
    "        # If not a NumPy array, convert it as before\n",
    "        tensor = torch.tensor([[int(bit) for bit in binary_array]], dtype=torch.float32)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, binary_sequences, targets, num_epochs, learning_rate, batch_size):\n",
    "    criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Calculate number of batches\n",
    "    num_batches = len(binary_sequences) // batch_size\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get batch data\n",
    "            batch_sequences = binary_sequences[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            batch_targets = targets[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Initialize hidden state for the batch with batch size\n",
    "            hidden = model.init_hidden(batch_size=batch_size)\n",
    "            \n",
    "            # Forward pass through each sequence in the batch\n",
    "            batch_loss = 0\n",
    "            \n",
    "            input_tensor = binary_array_to_tensor(batch_sequences)  # Prepare input tensor for batch\n",
    "            output, hidden = model(input_tensor, hidden)  # Forward pass\n",
    "             # Adjust dimensions if necessary\n",
    "            target_tensor = torch.tensor(batch_targets).float()\n",
    "            loss = criterion(output.squeeze(1), target_tensor)\n",
    "            batch_loss += loss.item()\n",
    "            \n",
    "            # Compute the average loss for the batch\n",
    "            batch_loss = batch_loss / batch_size\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "            # Backward pass and optimization step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/num_batches:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, binary_sequences, targets, batch_size):\n",
    "    model.eval()  # Set the model to evaluation mode (disable dropout, etc.)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for testing\n",
    "        # Calculate number of batches\n",
    "        num_batches = len(binary_sequences) // batch_size\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            # Get batch data\n",
    "            batch_sequences = binary_sequences[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            batch_targets = targets[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            \n",
    "            # Convert batch sequences to a tensor\n",
    "            input_tensor = torch.stack([binary_array_to_tensor(seq) for seq in batch_sequences])  # Shape: (batch_size, seq_length, input_size)\n",
    "            \n",
    "            # Initialize hidden state for the batch\n",
    "            hidden = model.init_hidden(batch_size=batch_size)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, hidden = model(input_tensor, hidden)\n",
    "            \n",
    "            # Convert outputs to binary predictions (0 or 1)\n",
    "            predictions = torch.round(outputs.squeeze()).int()  # Convert probabilities to binary\n",
    "            \n",
    "            # Check predictions against targets\n",
    "            for pred, target in zip(predictions, batch_targets):\n",
    "                if pred.item() == target:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = correct / total\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0023\n",
      "Epoch [2/10], Loss: 0.0021\n",
      "Epoch [3/10], Loss: 0.0020\n",
      "Epoch [4/10], Loss: 0.0020\n",
      "Epoch [5/10], Loss: 0.0020\n",
      "Epoch [6/10], Loss: 0.0020\n",
      "Epoch [7/10], Loss: 0.0020\n",
      "Epoch [8/10], Loss: 0.0020\n",
      "Epoch [9/10], Loss: 0.0020\n",
      "Epoch [10/10], Loss: 0.0020\n",
      "Test Accuracy: 74.43%\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "input_size = num_ancilla_qubits # Each input is a Detection round, vector of mmt of the Ancilla\n",
    "hidden_size =64  # You can experiment with different sizes\n",
    "output_size = 1  # Output is the value of the observable after the mmt cycles\n",
    "batch_size=256\n",
    "learning_rate=0.0005\n",
    "num_epochs=10\n",
    "\n",
    "# Create an instance of the RNN model\n",
    "model = BinaryRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train(model, X_train, y_train, num_epochs, learning_rate, batch_size)\n",
    "    \n",
    "test(model, X_test, y_test,batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90725\n"
     ]
    }
   ],
   "source": [
    "import pymatching\n",
    "\n",
    "detector_error_model = circuit_surface.detector_error_model(decompose_errors=True)\n",
    "matcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "\n",
    "detection_test=detection_events[-int(test_dataset_size):]\n",
    "observable_test=observable_flips[-int(test_dataset_size):]\n",
    "\n",
    "\n",
    "# Run the decoder with the test samples\n",
    "predictions = matcher.decode_batch(detection_test)\n",
    "\n",
    "# Count the mistakes.\n",
    "num_errors = 0\n",
    "for shot in range(int(test_dataset_size)):\n",
    "    actual_for_shot = observable_test[shot]\n",
    "    predicted_for_shot = predictions[shot][0]\n",
    "    if not np.array_equal(actual_for_shot, predicted_for_shot):\n",
    "        num_errors += 1\n",
    "\n",
    "print((test_dataset_size-num_errors)/test_dataset_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
